# 杂记

说明：该文档为日常的技术文档，以及自己喜欢的语录，不用来记录项目，放在桌面==勿动！勿动！勿动！==



## 语录

1. 为了表示我的忠诚，我特向领导保证：

   领导的要求就是我的追求、领导的鼓励就是我的动力、领导的想法就是我的做法、领导的表情就是我的心情、领导的嗜好就是我的爱好、领导的情人就是我的爱人！呕......

2. 打工人：

   爸，听说你最近换工作了，

   打工人，打工魂，打工都是人上人

   上班感觉是被生活所迫，没有灵魂，而打工则是对美好生活的向往

   打工是不可能打工的，这辈子是不可能打工的，做生意又不会，这里面的人都是人才，说话又好听

3. 百般乐器，唢呐为王，不是升天，就是拜堂，千年琵琶，万年筝，一把二胡拉一生，唢呐一响全剧终。曲一响，布一盖，全村老小等上菜，走的走，抬的抬，后面跟着一片白。棺一抬，土一埋，亲朋好友哭起来，鞭炮响，唢呐吹，前面抬，后面追，初闻不知唢呐意，再闻已是棺中人，两耳不闻棺外事，一心只蹦黄泉迪，一路嗨到阎王殿，从此不恋人世间

4. 九分喜欢，一分尊严，放下你，放过自己

5. 人生建议：别加，别聊，别撩，别爱，别碰，别喜欢，别见，别想，别习惯，别念，别哭，别留恋，别遗憾

6. 世界上只有一种英雄主义，那就是在认清生活真相后，依然热爱它

7. 你根本不是孤木，你根本不是孤掌，你一点都不孤单，这个问题是因为菜鸟足够弱，弱者在此场景中想崛起，若想为自己的权利抗争，你唯一的方法就是尽量发光，你不是相信这个光可以照亮一切，只是因为黑暗里的一点点光在远处会特别的耀眼，其他的光会看到你这扇光，微光会照亮微光，微光会吸引微光，我们相互找到，然后我们一起发光

8. 娉袅袅十三余，豆蔻梢头二月初

9. 池上碧苔三四点，叶底黄鹂一两声



## Dubbo

### 配置dubbo的管理平台

dubbo下载地址：https://codeload.github.com/apache/incubator-dubbo-ops/zip/master

配置参考：https://blog.csdn.net/cfydaniel/article/details/44980193

进入./dubbo-admin-master/dubbo-admin，编译执行`mvn clean package`，打成jar包，修改jar包中的application.properties文件。

```xml
dubbo.registry.adress=zookeeper://（zookeeper地址）
dubbo.registry.group=（dubbo分组名）
```

修改dubbo-admin.xml文件中的对应节点

```xml
<dubbo:registry group="${dubbo.registry.group}" address="${dubbo.registry.address}" check="false" file="false" />
```

起服务`java -jar xxx.jar`，打开`127.0.0.1:7001`，用户名/密码：root/root，即可看到服务消费者和服务提供者





## 配置notepad++

### 配置pluginmanager

从版本V7.1之后，notepad++没有plugin manager菜单，添加plugin manager菜单方法：

plugin manager下载地址：https://github.com/bruderstein/nppPluginManager/releases，选择PluginManager_v1.4.12_x64.zip，解压替换到安装目录中，重启即可

### 配置json插件

下载地址：https://github.com/zbeboy/Jsonviewer2/releases

将下载的dll文件粘贴到安装目录的plugins目录下即可





## google查看http请求与响应

打开开发者工具，选择network，然后选择xhr









## idea

查找restful请求，插件：restfultoolkit.jar

alibaba编码规范指引，插件：Alibaba Java Coding Guidelines

Free MyBatis Plugin:MyBatis扩展插件，可以在Mapper接口的方法和xml实现之间自由跳转，也可以用来一键生成某些xml实现。我们可以通过Mapper接口中方法左侧的箭头直接跳转到对应的xml实现中去；

MyBatis Log Plugin:有时候我们需要运行过程中产生的SQL语句来帮助我们排查某些问题，这款插件可以把Mybatis输出的SQL日志还原成完整的SQL语句，就不需要我们去手动转换了。



添加注释模板：参考[《IDEA注释模板》](https://gblfy.blog.csdn.net/article/details/90112417?utm_medium=distribute.pc_relevant_t0.none-task-blog-searchFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-searchFromBaidu-1.control)

1. 设置idea中类的模板：

   路径：File–>settings–>Editor–>File and Code Templates–>Files->Class

   样例：

   ```java
   /**
    *@Deacription TODO
    *@Author ${USER}
    *@Date ${DATE} ${TIME}
    *@Version 1.0
    **/
   
   ```

   截图：

   <img src="C:\Users\Charles Jian.Ma\Pictures\图库-----勿动\idea配置类注解.PNG" alt="idea配置类注解" style="zoom: 50%;" />

   

2. 设置方法注释模板：

   路径：File–>settings–>Editor–>live templates，操作截图如下：

   <img src="C:\Users\Charles Jian.Ma\Pictures\图库-----勿动\idea配置方法注解.jpg" alt="idea配置方法注解" style="zoom:50%;" />

   

   模板样例：

   ```java
   *
   * @Description //TODO
   * @Date $date$
   * @Param $param$
   * @return $return$
   **/ 
     
    
   ```

   

   

3. 将项目进行git管理：

   在项目上点击右键，选择git即可，此时文件均为红色，为未提交状态，将项目选中，点击add，加入到临时区，然后点击commit提交到本地库中，如需显示git窗口，点击view->tools->git即可

4. 配置spring-boot-devtools工具：

   模块来使Spring Boot应用支持热部署，提高开发者的开发效率，无需手动重启Spring Boot应用，依赖

   ```xm
   <!-- 热部署模块 -->
   <dependency>
       <groupId>org.springframework.boot</groupId>
       <artifactId>spring-boot-devtools</artifactId>
       <optional>true</optional> <!-- 这个需要为 true 热部署才有效 -->
   </dependency>
   ```

   参考https://blog.csdn.net/qq_34491508/article/details/83830075配置idea，

   

   

## ProcessON

画时序图，画类图工具







## zookeeper

ZooKeeper是一个[分布式](https://baike.baidu.com/item/分布式/19276232)的，开放源码的[分布式应用程序](https://baike.baidu.com/item/分布式应用程序/9854429)协调服务，是[Google](https://baike.baidu.com/item/Google)的Chubby一个[开源](https://baike.baidu.com/item/开源/246339)的实现，是Hadoop和[Hbase](https://baike.baidu.com/item/Hbase/7670213)的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。

ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。

ZooKeeper包含一个简单的原语集，提供Java和C的接口。

ZooKeeper代码版本中，提供了分布式独享锁、选举、队列的接口，代码在$zookeeper_home\src\recipes。其中分布锁和队列有[Java](https://baike.baidu.com/item/Java/85979)和C两个版本，选举只有Java版本。

下载地址：http://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz

### zookeeper原理

https://www.cnblogs.com/ultranms/p/9585191.html



<img src="D:\图库----可新增----不可删除\183233-20160316223234865-1124736424.png" alt="183233-20160316223234865-1124736424" style="zoom: 67%;" />

### zookeeper配置

zookeeper下载完成后解压到合适目录，然后进入到zookeeper的conf目录，找到zoo_sample.cfg文件将其重命名为zoo.cfg，然后打开该文件， 将其中的dataDir和dataLogDir修改如下：

`dataDir=E:\\Soft\\zookeeper-3.4.6\\data`

修改为你本地硬盘的目录，进入到zookeeper的bin目录下，双击zkServer.cmd,启动zookeeper

### zooKeeper与dubbo结合

请参考：https://blog.csdn.net/abcwanglinyong/article/details/81906027

### 说明：

在配置的时候出现问题，如zk连不上等各种原因，重启zookeeper服务即可



## kafka



参考了https://www.cnblogs.com/lnice/p/9668750.html

kafka的安装首先需要安装zookeeper，参考上文的安装即可，在此说明的是，在系统高级配置中需要配置java_home，否则会报错

### kafka环境搭建：

在参考该博客安装的时候，会报错，报错信息如下：

```java
kafka出现:

 Error while fetching metadata with correlation id  : {LEADER_NOT_AVAILABLE}

表示无法识别kafka hostname
```

报错的解决方案参考：

https://blog.csdn.net/luozhonghua2014/article/details/80369469

操作完成后，验证即可通过

### kafka使用：

首先启动zookeeper：`zkserver`

启动kafka：

`cd进kafka的安装目录中 `，执行`.\bin\windows\kafka-server-start.bat .\config\server.properties`



创建topic：

`kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test`

partitions：这个topic的partition的数量。

replication-factor：每个partition的副本个数。任意将每一个分区复制到n个broker上。

这个命令就是创建一个topic：haoxy1，只有1个partition，并且这个分区会部署在一个broker上

查看topic：

./bin/kafka-topics.sh --list --zookeeper （zk的ip）:2181

查看消息内容：

./kafka-console-consumer.sh --bootstrap-server （kafka1的ip）:9092,（kafka2的ip）:9092,（kafka3的ip）:9092 --from-beginning --topic （topic的名称）

​	说明：参数from-beginning表明所有消息，去掉该参数即可只消费正在写入的消息





生产者procedure：

`kafka-console-producer.bat --broker-list localhost:9092 --topic test`

消费者consumer：

`kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test --from-beginning`

### eagle使用



http://localhost:8048/ke





select * from "test" where "partition" in (0)





## redis：

Redis 是完全开源的，遵守 BSD 协议，是一个高性能的 key-value 数据库。

Redis 与其他 key - value 缓存产品有以下三个特点：

- Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。
- Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
- Redis支持数据的备份，即master-slave模式的数据备份。

### redis数据类型

redis存储数据类型：一共有7种，常用的有5种

| 类型                 | 类型简介                                               | 特性                                                         | 场景                                                         |
| -------------------- | ------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| String(字符串)       | 二进制安全                                             | 可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M | ---                                                          |
| Hash(字典)           | 键值对集合,即编程语言中的Map类型                       | 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) | 存储、读取、修改用户属性                                     |
| List(列表)           | 链表(双向链表)                                         | 增删快,提供了操作某一段元素的API                             | 1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列          |
| Set(集合)            | 哈希表实现,元素不重复                                  | 1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作 | 1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐 |
| Sorted Set(有序集合) | 将Set中的元素增加一个权重参数score,元素按score有序排列 | 数据插入集合时,已经进行天然排序                              | 1、排行榜 2、带权重的消息队列                                |
| 位图（Bitmap）       |                                                        |                                                              |                                                              |
| HyperLogLogs         |                                                        |                                                              |                                                              |

### redis数据操作

#### String（字符串）

string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。

string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。

string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。

##### 实例

```
redis 127.0.0.1:6379> SET runoob "菜鸟教程"
OK
redis 127.0.0.1:6379> GET runoob
"菜鸟教程"
```

在以上实例中我们使用了 Redis 的 **SET** 和 **GET** 命令。键为 runoob，对应的值为 **菜鸟教程**。

**注意：**一个键最大能存储 512MB。

------

#### Hash（哈希）

Redis hash 是一个键值(key=>value)对集合。

Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。

##### 实例

**DEL runoob** 用于删除前面测试用过的 key，不然会报错：**(error) WRONGTYPE Operation against a key holding the wrong kind of value**

![img](https://www.runoob.com/wp-content/uploads/2014/11/B104156B-7270-4D03-8EB3-B72D4022ED78.jpg)

```
redis 127.0.0.1:6379> DEL runoob
redis 127.0.0.1:6379> HMSET runoob field1 "Hello" field2 "World"
"OK"
redis 127.0.0.1:6379> HGET runoob field1
"Hello"
redis 127.0.0.1:6379> HGET runoob field2
"World"
```

实例中我们使用了 Redis **HMSET, HGET** 命令，**HMSET** 设置了两个 **field=>value** 对, HGET 获取对应 **field** 对应的 **value**。

每个 hash 可以存储 232 -1 键值对（40多亿）。



------

#### List（列表）

Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。

##### 实例

```
redis 127.0.0.1:6379> DEL runoob
redis 127.0.0.1:6379> lpush runoob redis
(integer) 1
redis 127.0.0.1:6379> lpush runoob mongodb
(integer) 2
redis 127.0.0.1:6379> lpush runoob rabitmq
(integer) 3
redis 127.0.0.1:6379> lrange runoob 0 10
1) "rabitmq"
2) "mongodb"
3) "redis"
redis 127.0.0.1:6379>
```

列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。

------

#### Set（集合）

Redis 的 Set 是 string 类型的无序集合。

集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。

##### sadd 命令

添加一个 string 元素到 key 对应的 set 集合中，成功返回 1，如果元素已经在集合中返回 0。

```
sadd key member
```

##### 实例

```
redis 127.0.0.1:6379> DEL runoob
redis 127.0.0.1:6379> sadd runoob redis
(integer) 1
redis 127.0.0.1:6379> sadd runoob mongodb
(integer) 1
redis 127.0.0.1:6379> sadd runoob rabitmq
(integer) 1
redis 127.0.0.1:6379> sadd runoob rabitmq
(integer) 0
redis 127.0.0.1:6379> smembers runoob

1) "redis"
2) "rabitmq"
3) "mongodb"
```

**注意：**以上实例中 rabitmq 添加了两次，但根据集合内元素的唯一性，第二次插入的元素将被忽略。

集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。

------

#### zset(sorted set：有序集合)

Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。



不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。

zset的成员是唯一的,但分数(score)却可以重复。

##### zadd 命令

添加元素到集合，元素在集合中存在则更新对应score

```
zadd key score member 
```

##### 实例

```
redis 127.0.0.1:6379> DEL runoob
redis 127.0.0.1:6379> zadd runoob 0 redis
(integer) 1
redis 127.0.0.1:6379> zadd runoob 0 mongodb
(integer) 1
redis 127.0.0.1:6379> zadd runoob 0 rabitmq
(integer) 1
redis 127.0.0.1:6379> zadd runoob 0 rabitmq
(integer) 0
redis 127.0.0.1:6379> > ZRANGEBYSCORE runoob 0 1000
1) "mongodb"
2) "rabitmq"
3) "redis"
```

## 监控

监控的功能模块：

​	prometheus（普罗米修斯）：分布式监控系统

​	ELK：elasticsearch、logstash、kiban三个开源软件组合，日志分析平台，logstash采集日志，elasticsearch提取关键字

​	zabbix：基于关键字去做报警

​	grafana：日志监控可视层 

​	skywalking：分布式服务追踪系统

​	prometheus（普罗米修斯）、ELK、zabbix为同种用途的不同的三个产品



## 数据库









### plsql

#### 中文乱码问题：

参考文档：https://blog.csdn.net/guanjintao/article/details/80758642

（后续整理）



#### plsql事务

​	事务不是自动提交的，需要手动提交

#### 表被锁处理方案

plsql由于事务未提交，导致表被锁解决方法：

参考文档：https://blog.csdn.net/nmjuzi/article/details/80353670



#### plsql查询条件为日期：

to_date()





### mybatis：

mybatis开发步骤：

- 添加pom依赖
- 在resources中写**Map.xml
- 增加dao层的interface，以及对应的entity
- 增加mybatis的配置类，指定扫描包的位置，同时需要修改spring boot的application.yml配置文件

因为步骤较为固定，因此也可以通过mybatis-generator插件生成

详细步骤：

1. mybatis的pom依赖

   ```xml
    <!--mybatis插件依赖-->
   <dependency>
       <groupId>org.mybatis.spring.boot</groupId>
       <artifactId>mybatis-spring-boot-starter</artifactId>
       <version>2.1.4</version>
   </dependency>
   
   <dependency>
       <groupId>org.mybatis</groupId>
       <artifactId>mybatis</artifactId>
       <version>3.5.6</version>
   </dependency>
   
   <!--分页插件pagehelper-->
   <dependency>
       <groupId>com.github.pagehelper</groupId>
       <artifactId>pagehelper-spring-boot-starter</artifactId>
       <version>1.3.0</version>
   </dependency>
   
   ```

2. Mybatis-generator:

   Mybatis-Generator可以帮助我们自动生成很多结构化的代码，比如每张表对应的Entity、Mapper接口和Xml文件，可以省去很多繁琐的工作，加快了开发速度，使用方面根据其提供的规则配置好就OK，这里还有一个重要的开发场景，开发过程中，对数据库的操作肯定很多，比如新增字段什么的，你只要将原先自动生成的一套代码删除，重新再生成一份，这就完美解决了，但是这样做的前提是，你必须对生成后的代码不改动，只是使用。不需要想手动开发写代码那样到处改代码，还担心改漏地方，其实这个的实现方式也是五花八门的，介绍一种比较常见的

   - 准备工作

     在pom文件中添加插件依赖,需要注意的是将plugins放到与pluginmanagement同级，否则不显示generator插件参考如下设置

     ```xml
     <pluginManagement>
     .....
     </pluginManagement>
     <plugins>
         <plugin>
             <groupId>org.mybatis.generator</groupId>
             <artifactId>mybatis-generator-maven-plugin</artifactId>
             <version>1.4.0</version>
             <configuration>
                 <configurationFile>${basedir}/src/main/resources/generatorConfig.xml</configurationFile>
                 <overwrite>true</overwrite>
                 <verbose>true</verbose>
             </configuration>
             <dependencies>
                 <dependency>
                     <groupId>mysql</groupId>
                     <artifactId>mysql-connector-java</artifactId>
                     <version>8.0.22</version>
                 </dependency>
             </dependencies>
         </plugin>
     </plugins>
     ```

   - 将mybatis-generator配置文件放入resource/generator目录下，文件名为generatorConfig.xml，内容如下:

     ```xml
     <?xml version="1.0" encoding="UTF-8"?>
     <!DOCTYPE generatorConfiguration
             PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN"
             "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd">
     <generatorConfiguration>
         <context id="default" targetRuntime="MyBatis3">
             <!-- 生成mysql带有分页的sql的插件  这个可以自己写，-->
             <!--        <plugin type="generator.MysqlPaginationPlugin" />-->
             <!--        <plugin type="org.mybatis.generator.plugins.ToStringPlugin" />-->
             <!--        <plugin type="org.mybatis.generator.plugins.SerializablePlugin" />-->
             <!-- 自定义的注释规则，继承 DefaultCommentGenerator 重写 一些方法 -->
             <commentGenerator>
                 <!-- 是否去除自动生成日期的注释 true：是 ： false:否 -->
                 <property name="suppressDate" value="true"/>
                 <!-- 是否去除所有自动生成的注释 true：是 ： false:否 -->
                 <property name="suppressAllComments" value="true"/>
             </commentGenerator>
             <!--数据库链接URL，用户名、密码 -->
             <jdbcConnection driverClass="com.mysql.cj.jdbc.Driver" connectionURL="jdbc:mysql://localhost/appinaction"
                             userId="test"
                             password="">
             </jdbcConnection>
             
             <!--生成entity类存放位置-->
             <javaModelGenerator targetPackage="org.example.entity" targetProject="src/main/java">
                 <property name="enableSubPackages" value="true"/>
                 <property name="trimStrings" value="true"/>
             </javaModelGenerator>
     
             <!--生成映射文件存放位置-->
             <sqlMapGenerator targetPackage="org.example.map" targetProject="src/main/resources">
                 <property name="enableSubPackages" value="true"/>
             </sqlMapGenerator>
             <!--生成Dao类存放位置-->
             <javaClientGenerator type="XMLMAPPER" targetPackage="org.example.dao"
                                  targetProject="src/main/java">
                 <property name="enableSubPackages" value="true"/>
             </javaClientGenerator>
             <!-- 要生成的表 tableName是数据库中的表名或视图名 domainObjectName是实体类名-->
             <table tableName="book" domainObjectName="Book">
             </table>
         </context>
     </generatorConfiguration>
     ```

     说明：

     属性targetPackage的值为包名，且包名可以是不存在的，他会自动创建，属性targetProject的值为项目目录名，且必须是已存在的，否则会报错，targetProject的值的起始目录为当前子模块目录，在maven多模块项目中可以利用相对目录切换到同级子模块下，如../shopping_bean/src/main/java

     需要修改的部分为：

     数据库的url以及用户名密码，生成模型的包名和位置，生成映射文件的包名和位置，生成DAO的包名和位置，添加要生成的表。

   - 运行插件，生成代码，其中插件位置在MavenProject中的Plugins下

   - 查看entity以及mapper，大功告成

3. 步骤2为通过mybatis-generator插件生成代码，还会存在需要自己编写mapper的情况，在此介绍一下自己手动编写的方式

  参考样例，需要修改namespace、select id、 resultMap，namespace为interface的位置，select id 为接口的方法名，resultMap为生成的结果类。

  ```xml
  <?xml version="1.0" encoding="UTF-8"?>
  <!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
  <mapper namespace="com.majian.mall.dao.UmsAdminRoleRelationDao">
      <select id="getPermissionList" resultMap="com.majian.mall.mbg.mapper.UmsPermissionMapper.BaseResultMap">
          SELECT
              p.*
          FROM
              ums_admin_role_relation ar
              LEFT JOIN ums_role r ON ar.role_id = r.id
              LEFT JOIN ums_role_permission_relation rp ON r.id = rp.role_id
              LEFT JOIN ums_permission p ON rp.permission_id = p.id
          WHERE
              ar.admin_id = #{adminId}
              AND p.id IS NOT NULL
              AND p.id NOT IN (
                  SELECT
                      p.id
                  FROM
                      ums_admin_permission_relation pr
                      LEFT JOIN ums_permission p ON pr.permission_id = p.id
                  WHERE
                      pr.type = - 1
                      AND pr.admin_id = #{adminId}
              )
          UNION
          SELECT
              p.*
          FROM
              ums_admin_permission_relation pr
              LEFT JOIN ums_permission p ON pr.permission_id = p.id
          WHERE
              pr.type = 1
              AND pr.admin_id = #{adminId}
      </select>
  </mapper>
  ```

  

4. pagehelper使用

   ----todo

   

5. 修改application.yml文件

在根结点增加如下配置，注意mapper-locations指定了mapper文件的位置，需要根据项目的具体位置修改

```yml
mybatis:
  mapper-locations:
    - classpath:mapper/*.xml
    - classpath*:com/**/mapper/*.xml
```



 

参考文档：

https://blog.csdn.net/qq_33530388/article/details/71194518

https://www.cnblogs.com/charlypage/p/11220755.html

https://blog.csdn.net/qq827245563/article/details/88424357

https://www.jianshu.com/p/93a9a37be576

https://www.cnblogs.com/jpfss/p/8918315.html

（后续整理）







### mysql高可用搭建

https://blog.51cto.com/sumongodb/1953244

https://www.cnblogs.com/dion-90/articles/9053976.html

https://www.cnblogs.com/yeyusheng/p/8623097.html

https://www.cnblogs.com/charlypage/p/11220755.html



### mysql安装：

安装前准备：

1. 查看是否安装了mysql：

   `rpm -qa | grep mysql`

   如果已安装，需卸载，卸载命令如下：

   ```shell
   rpm -e mysql　　// 普通删除模式
   rpm -e --nodeps mysql　　// 强力删除模式，如果使用上面命令删除时，提示有依赖的其它文件，则用该命令可以对其进行强力删除
   ```

2. 顺序安装如下包

   ```shell
   mysql安装包地址：https://dev.mysql.com/downloads/mysql/RPM Bundle包
   
   mysql-community-common-5.7.18-1.el7.x86_64.rpm
   
   mysql-community-libs-5.7.18-1.el7.x86_64.rpm
   
   mysql-community-client-5.7.18-1.el7.x86_64.rpm  
   
   mysql-community-server-5.7.18-1.el7.x86_64.rpm
   
   mysql-community-devel-5.7.18-1.el7.x86_64.rpm
   #安装命令如下
   rpm -ivh mysql-community-common-5.7.18-1.el7.x86_64.rpm
   
   rpm -ivh mysql-community-libs-5.7.18-1.el7.x86_64.rpm
   
   rpm -ivh mysql-community-client-5.7.18-1.el7.x86_64.rpm  
   
   rpm -ivh mysql-community-server-5.7.18-1.el7.x86_64.rpm 
   
   rpm -ivh mysql-community-devel-5.7.18-1.el7.x86_64.rpm
   ```

3. 启动mysql：

   `service mysqld start`

4. 查看日志：

   `tail -fn 200 var/log/mysqld.log（注意： 是 mysqld.log 不是mysql.log）`

   查看初始密码：

   `	cat /var/log/mysqld.log | grep 'temporary password'`

5. 登陆mysql：

   mysql -uroot -pXXX

6. 登陆时会报密码已过期，解决方案：

   说明：

   mysql5.7  mysql库下面的user表没有password字段无法修改密码，password字段被改为authentication_string（参考：https://www.cnblogs.com/benjamin77/p/8681763.html）

   1. 停止mysql：

      service mysqld stop

   2. 修改my.inf：

      vim /etc/my.cnf

      在my.cnf中

      [mysqld]节点下添加

      skip-grant-tables

      改为无密码登陆

      重启mysql服务

   3. 登陆

      ```shell
      mysql -uroot -p
      update mysql.user set password_expired='N' where user='root';
      use mysql
      update user set authentication_string=password('123') where user='root';
      exit
      ```

      ​	

   4. 然后将skip-grant-tables去掉,重启mysql服务

      service mysqld restart

   5. 登陆mysql：

      用密码‘123’登陆即可

7. 查看mysql运行状态：

   service mysqld status

8. 查看用户表：

   ```mysql
   user mysql;
   select host, user from user;
   ```

   

### mysql使用

新建用户：

**一, 创建用户:**

**命令:CREATE USER 'username'@'host' IDENTIFIED BY 'password';**

说明:username - 你将创建的用户名, host - 指定该用户在哪个主机上可以登陆,如果是本地用户可用localhost, 如果想让该用户可以从任意远程主机登陆,可以使用通配符%. password - 该用户的登陆密码,密码可以为空,如果为空则该用户可以不需要密码登陆服务器.

例子: CREATE USER 'dog'@'localhost' IDENTIFIED BY '123456';
CREATE USER 'pig'@'192.168.1.101_' IDENDIFIED BY '123456';
CREATE USER 'pig'@'%' IDENTIFIED BY '123456';
CREATE USER 'pig'@'%' IDENTIFIED BY '';
CREATE USER 'pig'@'%';



**二,授权:**

**命令:GRANT privileges ON databasename.tablename TO 'username'@'host'**

说明: privileges - 用户的操作权限,如SELECT , INSERT , UPDATE 等(详细列表见该文最后面).如果要授予所的权限则使用ALL.;databasename - 数据库名,tablename-表名,如果要授予该用户对所有数据库和表的相应操作权限则可用\*表示, 如\*.\*.

例子: GRANT SELECT, INSERT ON test.user TO 'pig'@'%';
GRANT ALL ON \*.* TO 'pig'@'%';

注意:用以上命令授权的用户不能给其它用户授权,如果想让该用户可以授权,用以下命令:
GRANT privileges ON databasename.tablename TO 'username'@'host' WITH GRANT OPTION;



**三.设置与更改用户密码**

**命令:SET PASSWORD FOR 'username'@'host' = PASSWORD('newpassword');如果是当前登陆用户用SET PASSWORD = PASSWORD("newpassword");**

例子: SET PASSWORD FOR 'pig'@'%' = PASSWORD("123456");



**四.撤销用户权限**

**命令: REVOKE privilege ON databasename.tablename FROM 'username'@'host';**

说明: privilege, databasename, tablename - 同授权部分.

例子: REVOKE SELECT ON *.* FROM 'pig'@'%';

注意: 假如你在给用户'pig'@'%'授权的时候是这样的(或类似的):GRANT SELECT ON test.user TO 'pig'@'%', 则在使用REVOKE SELECT ON *.* FROM 'pig'@'%';命令并不能撤销该用户对test数据库中user表的SELECT 操作.相反,如果授权使用的是GRANT SELECT ON *.* TO 'pig'@'%';则REVOKE SELECT ON test.user FROM 'pig'@'%';命令也不能撤销该用户对test数据库中user表的Select 权限.

具体信息可以用命令SHOW GRANTS FOR 'pig'@'%'; 查看.



附表:MySQL中的操作权限 



| 权限key                  | 权限说明                                                     |
| ------------------------ | ------------------------------------------------------------ |
| ALTER                    | Allows use of alter table                                    |
| `ALTER ROUTINE`          | Alters or drops stored routines.                             |
| `CREATE`                 | Allows use of `CREATE TABLE`.                                |
| `CREATE ROUTINE`         | Creates stored routines.                                     |
| `CREATE TEMPORARY TABLE` | Allows use of `CREATE TEMPORARY TABLE`.                      |
| `CREATE USER`            | Allows use of `CREATE USER`, `DROP USER`, `RENAME USER`, and `REVOKE ALL PRIVILEGES`. |
| `CREATE VIEW`            | Allows use of `CREATE VIEW`.                                 |
| `DELETE`                 | Allows use of `DELETE`.                                      |
| `DROP`                   | Allows use of `DROP TABLE`.                                  |
| `EXECUTE`                | Allows the user to run stored routines.                      |
| `FILE`                   | Allows use of `SELECT`... `INTO OUTFILE` and `LOAD DATA INFILE`. |
| `INDEX`                  | Allows use of `CREATE INDEX` and `DROP INDEX`.               |
| `INSERT`                 | Allows use of `INSERT`.                                      |
| `LOCK TABLES`            | Allows use of `LOCK TABLES` on tables for which the user also has `SELECT` privileges. |
| `PROCESS`                | Allows use of `SHOW FULL PROCESSLIST`.                       |
| `RELOAD`                 | Allows use of `FLUSH`.                                       |
| `REPLICATION`            | Allows the user to ask where slave or master                 |
| `CLIENT`                 | servers are.                                                 |
| `REPLICATION SLAVE`      | Needed for replication slaves.                               |
| `SELECT`                 | Allows use of `SELECT`.                                      |
| `SHOW DATABASES`         | Allows use of `SHOW DATABASES`.                              |
| `SHOW VIEW`              | Allows use of `SHOW CREATE VIEW`.                            |
| `SHUTDOWN`               | Allows use of `mysqladmin shutdown`.                         |
| `SUPER`                  | Allows use of `CHANGE MASTER`, `KILL`, `PURGE MASTER LOGS`, and `SET GLOBAL` SQL statements. Allows `mysqladmin debug` command. Allows one extra connection to be made if maximum connections are reached. |
| `UPDATE`                 | Allows use of `UPDATE`.                                      |
| `USAGE`                  | Allows connection without any specific privileges.           |

### 

```shell
--进入sql服务后首先查看有哪些数据库
show databases;

--若没有新建一个
CREATE DATABASE library;

--删除数据库
DROP DATABASE [ IF EXISTS ] <数据库名>

--使用数据库
use library;

--查看有哪些表
show tables;

--新建表：CREATE TABLE xxxx();
--书：书名和作者
CREATE TABLE book(name char(20),author char(20));
--读者：人名、借书日期以及性别
CREATE TABLE reader(name char(20),date int(10),sex char(5));


--查看表的内容：SELECT * FROM xxx;
SELECT * FROM book;
SELECT * FROM reader;

--插入内容到表：INSERT INTO xxx VALUES();
INSERT INTO book VALUES('c language','niuren')
INSERT INTO book VALUES('java','lihairen')
INSERT INTO book VALUES('python','yjj')

INSERT INTO reader VALUES('kumata'.20180530,'man');
INSERT INTO reader(name,sex) VALUES('kusada','man');
INSERT INTO reader(name,date) VALUES('wuyifan',20187475);

--再查看
SELECT * FROM book;

--删除所有行：
delete from TableName

--计算符合条件的行数：
select count（*）from tableName where ……..

```



sql 语句顺序：

```sql
select * from table1 ......on....... where .... group by ......having....... 
```

sql 执行顺序：

```sql
from... where...group by... having.... select ... order by... limit
```

因为where执行顺序在聚合函数之前，所以不能在where的筛选条件中有聚合函数，如需聚合函数，则用having



mysql驱动：

MySQL5用的驱动url是com.mysql.jdbc.Driver，MySQL6以后用的是com.mysql.cj.jdbc.Driver，版本不匹配便会报驱动类已过时的错误。



### mysql主从搭建

两台已搭建mysql服务的服务器：

**192.168.56.100**

**192.168.56.101**

1. 增加主从同步账号：

   ```mysql
   grant replication slave on *.* to 'bak'@'192.168.56.%' identified by '123456';
   
   flush privileges;
   ```

   会报错，报密码不符合规定，解决方案参考https://www.cnblogs.com/ios9/p/9716478.html。

2. 配置同步信息：

   先在192.168.56.101上：

   `CHANGE MASTER TO MASTER_HOST='192.168.56.100',MASTER_USER='bak',MASTER_PASSWORD='123456',master_auto_position=1;`

   会报错：

   查看用户权限：

   `show grants for bak@'172.16.%.%' `

   查看server_id:

   `show variables like '%server_id%`,此处server_id不能相同，需要修改为不同的值，且不能为0

   修改server_id:

   1. 修改my.inf：

      vim /etc/my.cnf

   2. 在my.cnf中：

      [mysqld]节点下添加如下内容：

      ```
      server-id=2   //给数据库服务的唯一标识，一般为大家设置服务器Ip的末尾号
      gtid_mode=on
      enforce_gtid_consistency=on
      
      #binlog
      log-bin=master-bin
      #rela log
      skip_slave_start=1
      ```

       `SHOW MASTER STATUS;`

3. 打开主从同步开关：

   `start slave；`

4. 查看主从同步状态：

   `show slave status\G;`

   ```bash
   从库两个工作的线程：IO，SQL都为yes，代表同步搭建成功
   Slave_IO_Running: Yes
   Slave_SQL_Running: Yes
   ```

   实际操作过程中slave_IO_Running为no

   是由于master的serer id 为0，将master的server id修改为非0即可

5. 建数据库，建表验证





### keeplived安装



1. 解压tar文件,执行如下命令，会有报警

   `./configure --prefix=/usr/apps/keepalived --sysconf=/etc`

   安装libnl：

   ```shell
   ./configure --prefix=/usr     \
               --sysconfdir=/etc \
               --disable-static  &&
   make
   
   make install
   ```

   安装libnl-dev：

   ```shell
   rpm -ivh libnl3-devel-3.2.21-8.el6......rpm
   rpm -ivh libnl3-cli-3.2.21-8.el6........rpm
   ```

   再次执行第一步命令，无报警信息，执行：

   `make && make install `

2. 拷贝文件：

   ```shell
   cp /usr/local/keepalived-1.3.9/etc/sysconfig/keepalived /etc/sysconfig/
   mkdir /etc/keepalived
   cp /usr/local/keepalived-1.3.9/etc/keepalived/keepalived.conf /etc/keepalived/
   cp /usr/local/keepalived-1.3.9/sbin/keepalived /usr/sbin
   
   ```

3. 添加文件

   ```shell
   `# vi /etc/init.d/keepalived`
   ```

   脚本内容如下：

   ```shell
   #!/bin/sh 
   # 
   # keepalived   High Availability monitor built upon LVS and VRRP 
   # 
   # chkconfig:   - 86 14 
   # description: Robust keepalive facility to the Linux Virtual Server project \ 
   #              with multilayer TCP/IP stack checks. 
      
   ### BEGIN INIT INFO 
   # Provides: keepalived 
   # Required-Start: $local_fs $network $named $syslog 
   # Required-Stop: $local_fs $network $named $syslog 
   # Should-Start: smtpdaemon httpd 
   # Should-Stop: smtpdaemon httpd 
   # Default-Start:  
   # Default-Stop: 0 1 2 3 4 5 6 
   # Short-Description: High Availability monitor built upon LVS and VRRP 
   # Description:       Robust keepalive facility to the Linux Virtual Server 
   #                    project with multilayer TCP/IP stack checks. 
   ### END INIT INFO 
      
   # Source function library. 
   . /etc/rc.d/init.d/functions 
      
   exec="/usr/sbin/keepalived" 
   prog="keepalived" 
   config="/etc/keepalived/keepalived.conf" 
      
   [ -e /etc/sysconfig/$prog ] && . /etc/sysconfig/$prog 
      
   lockfile=/var/lock/subsys/keepalived 
      
   start() { 
       [ -x $exec ] || exit 5 
       [ -e $config ] || exit 6 
       echo -n $"Starting $prog: " 
       daemon $exec $KEEPALIVED_OPTIONS 
       retval=$? 
       echo 
       [ $retval -eq 0 ] && touch $lockfile 
       return $retval 
   } 
      
   stop() { 
       echo -n $"Stopping $prog: " 
       killproc $prog 
       retval=$? 
       echo 
       [ $retval -eq 0 ] && rm -f $lockfile 
       return $retval 
   } 
      
   restart() { 
       stop 
       start 
   } 
      
   reload() { 
       echo -n $"Reloading $prog: " 
       killproc $prog -1 
       retval=$? 
       echo 
       return $retval 
   } 
      
   force_reload() { 
       restart 
   } 
      
   rh_status() { 
       status $prog 
   } 
      
   rh_status_q() { 
       rh_status &>/dev/null 
   } 
      
      
   case "$1" in 
       start) 
           rh_status_q && exit 0 
           $1 
           ;; 
       stop) 
           rh_status_q || exit 0 
           $1 
           ;; 
       restart) 
           $1 
           ;; 
       reload) 
           rh_status_q || exit 7 
           $1 
           ;; 
       force-reload) 
           force_reload 
           ;; 
       status) 
           rh_status 
           ;; 
       condrestart|try-restart) 
           rh_status_q || exit 0 
           restart 
           ;; 
       *) 
           echo $"Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload}" 
           exit 2 
   esac 
   exit $?
   
   ```

   `chmod a+x /etc/init.d/keepalived`

4. 运行keepalive

   ```bash
   /etc/init.d/keepalived start
   ```

5. keepalive查看启动日志：

   tail -f /var/log/messages

   

### keepalived配置

修改配置文件，参考文档：https://blog.csdn.net/lpp_dd/article/details/81029104

修改keepalive的配置文件如下：

参考文档：https://blog.csdn.net/gjjumin/article/details/80800957

```shell
vim /etc/keepalived/keepalived.conf
#待完善

内容如下：
! Configuration File for keepalived

global_defs {
   router_id mysql-10.20
}

vrrp_instance VI_1 {
    state BACKUP
    interface eth2 #ip a 查看，与本地对应
    virtual_router_id 88 #该值随机不定，但是同一个集群需要保持一致
    priority 100 #优先级，备机改为90
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        172.16.10.44
    }
}

virtual_server 172.16.10.44 3306 {
    delay_loop 6
    lb_algo rr
    lb_kind NAT
    nat_mask 255.255.255.0
    persistence_timeout 50
    protocol TCP

    real_server 172.16.10.20 3306 {
        weight 1
        notify_down /home/admin/majian/mysql.sh #当real_server不可用的时候，执行脚本
        TCP_CHECK {
              connect_timeout 10
              nb_get_retry 3
              delay_before_retry 3
              connect_port 3306
        }
    }
} 

###特别需要注意的地方：
###注意有空格，否则不成功
```

重启keepalived，查看是否配置成功：`ip a`出现两个对应的虚拟ip即为部署成功！

需要注意的是，注意空格，参考文档：https://blog.csdn.net/zhmailm/article/details/81905739

具体参数解析：

```主要参数：
router-id:mysql-10.20 主机标识符；
state:BACKUP 表示keepalived角色，都是设成BACKUP则以优先级为主要参考；
virtual_router_id:  虚拟路由标识，取值0-255，master-1和master-2保持一致；
priority: 90  优先级，用来选举master，取值范围1-255；
advert_int: 1 发VRRP包时间间隔，即多久进行一次master选举；
nopreempt:不抢占，即允许一个priority值比较低的一个节点作为master;
delay_loop: 2 设置运行情况检查时间，单位为秒；
lb_algorr:  设置后端调度器算法，rr为轮询算法；
lb_kindDR:  设置LVS实现负载均衡的机制，有DR、NAT、TUN三种模式可选；
persistence_timeout: 60 会话保持时间，单位为秒；
protocol TCP 指定转发协议，有 TCP和UDP可选；
notify_down 检查mysql服务down掉后执行的脚本；
以上参数中router_id、priority和real_server三处不同，其他部分都相同。
```

当mysql进程死掉的时候，在重新启动时，需要进入mysql中，查看slave状态，show slave status\G;执行stop slave和start slave；数据即可同步



### postgresql

数据库表名，字段名必须为小写英文，不能有大写









## Markdown语法介绍

这篇文章是我第一次使用typora写的文章，主要是记录Markdown的相关语法，方便以后写文章与后续的查询。

主要包含一下功能：

1. 标题格式
2. 粗体与斜体
3. 插入数学公式
4. 插入代码c++/python等
5. 列表-有序表和无序表（待补充）
6. 插入图片和链接（待补充）
7. 插入表格

马建2017年11月16日于上海

### 标题格式

如本篇文章所示，标题有一级标题，二级标题，三级标题，四级标题等，在文本前加“#”即可，如 “#标题格式”（引号里面的内容为输入），在文本前输入‘#’的个数就是标题的级数

一级标题：‘#’

二级标题：‘##’

三级标题：‘###’

四级标题：‘####’

### 粗体和斜体

粗体和斜体主要是通过`*`实现的，用 “`** ` ……`**`  ”包含一段文本，该文本即**粗体**，用`*` …….`*`包含文本即为*斜体*

```** hello, world**```//粗体显示

`*hello, world*`//斜体显示

### 插入数学公式

数学公式以`$$…..$$`，其中省略号为待输入的公式，其中：

下标：如公式中i=0的样式，用`_{i=0}`，下划线加{}，{}中写下划线部分的内容

上标：如公式中n的样式，用`^n`， 上三角加{},{}中写上标的内容

`$$c=\sum_{i = 0}^{n= 9}x_i*y$$`

$$c=\sum_{i = 0}^{n =9}x_i*y$$

$$lim_{i \to 3}x=8$$

### 插入代码c++/python等

作为一位程序猿，最常见的莫过于添加代码，

如果引用的语句只有一段，不分行，用**`**。。**`**一个顿号将语句包起来，

如果有多行，在代码的开始与末尾用**```**三个顿号将语句包含，首先输入语言，回车，然后在输入要输入的代码

`int x `

`int y`

```c++
int x;
int y;
int f = x + y
```


### 有序/无序列表

有序列表输入方法：` 数字 + 点 + 空格`

1. `1. `
2. `2.`
3. `3.`
4. ……………..



无序列表输入方法：`- + 空格`

- adf

- adfa



### 下划线

输入方式 `<u>+内容+</u>`

<u>hello world!!!</u>



### 超链接

输入方式:`[]()`

	`[]`放入链接的文本,`()`放链接的地址

[markdown语法说明](https://segmentfault.com/a/1190000006247465)



### 高亮

输入方式：`== +内容+ ==`

==高亮==



### 流程图



```flow
st=>start: 开始
rain?=>condition: 今天有雨吗？
takeAnUmbrella=>operation: 带伞
go=>operation: 出门
e=>end: 结束

st->rain?
rain?(yes)->takeAnUmbrella->go
rain?(no)->go->e
```

[流程图语法](https://segmentfault.com/a/1190000006247465)

​	

### 表格输入

```
|姓名|性别|毕业学校|工资|
|:---|:---:|:---:|---:|
|杨洋|男|重庆交通大学|3200|
|峰哥|男|贵州大学|5000|
|坑货|女|北京大学|2000|
```









## java基础

== 与equals的区别

基本类型：



引用类型：





jsonstring与object的互相转换：

采用阿里巴巴的fastjson的类库

```xml
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>fastjson</artifactId>
    <version>1.2.4</version>
</dependency>
```



使用方法如下：

```java
 JSON.parseObject(User.toString(), User.class);
```









容器：

**Collection** 接口的接口 对象的集合（单列集合）
├——-**List** 接口：元素按进入先后有序保存，可重复
│—————-├ **LinkedList** 接口实现类， 链表， 插入删除， 没有同步， 线程不安全
│—————-├ **ArrayList** 接口实现类， 数组， 随机访问， 没有同步， 线程不安全
│—————-└ **Vector** 接口实现类 数组， 同步， 线程安全
│ ———————-└ **Stack** 是Vector类的实现类
└——-**Set** 接口： 仅接收一次，不可重复，并做内部排序
├—————-└**HashSet** 使用hash表（数组）存储元素
│————————└ **LinkedHashSet** 链表维护元素的插入次序
└ —————-**TreeSet** 底层实现为二叉树，元素排好序

**Map** 接口 键值对的集合 （双列集合）
├———**Hashtable** 接口实现类， 同步， 线程安全
├———**HashMap** 接口实现类 ，没有同步， 线程不安全-
├ ——–**TreeMap** 红黑树对所有的key进行排序

Object类中的hashCode()的方法是所有子类都会继承这个方法，这个方法会用Hash算法算出一个Hash（哈希）码值返回，HashSet会用Hash码值去和数组长度取模， 模（这个模就是对象要存放在数组中的位置）相同时才会判断数组中的元素和要加入的对象的内容是否相同，如果不同才会添加进去。





### java注解：

@Qualifier("[XXX](https://www.baidu.com/s?wd=XXX&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1dhP1R1uhwbnhubn1f3PHc0IAYqnWm3PW64rj0d0AP8IA3qPjfsn1bkrjKxmLKz0ZNzUjdCIZwsrBtEXh9GuA7EQhF9pywdQhPEUiqkIyN1IA-EUBtkrj6zPHb3nH0LPH01P1Tkn103)") Spring的Bean注入配置注解，该注解指定注入的Bean的名称





## jvm

java运行时的内存区域：

堆、jvm栈、本地栈、程序计数器、方法区



栈：有多个栈帧，栈帧



堆：



垃圾回收机制：



类加载机制：

加载、链接（验证、准备、解析）、初始化、使用、卸载



什么时候进行类初始化、以及类初始化顺序？



类加载器？



-

## Mac快捷键

这篇文档的主要是为了解决mac与windows之间的区别，用于快速查询快捷键

---

1. 截屏： Command + shift + 4（截取屏幕，同时保存到桌面上）

2. 锁屏：control + shift + 电源键

3. 看图 单击+空格

4. 命令行查看外接硬盘上的文件：

   ```shell
   cd /Volumes/ 
   ```

5. mac清理系统垃圾文件

   ```shell
   su //////su到超级用户
   du -sh * 查看当前目录下的文件以及文件夹的大小
   cd 进去
   找到自己熟悉的文件夹删除
   重启电脑
   
   ```

6. 查看mac文件路径

   https://jingyan.baidu.com/article/db55b609cd0dbd4ba30a2fcd.html

7. mac删除键：

   第一种：按 delete 键，实现 Windows 键盘上退格键的功能，也就是删除光标之前的一个字符（默认）；

   第二种：按 fn+delete 键，删除光标之后的一个字符；

   第三种：按 option+delete 键，删除光标之前的一个单词（英文有效）；

   第四种：结合第二种，按住fn+option+delete，删除光标之后的一个单词；

   第五种：选中文件后按 command+delete，删除掉该文件

8. 显示桌面：

   command + f3或者fn+f11



## Linux

解压缩文件命令： tar xvf



### gcc编译

==**语法**==

gcc (选项) (参数)



==**选项**==

-o：指定生成的输出文件

-E：仅执行编译预处理

-S：将c代码转换为汇编代码

-wall：显示警告信息

-c：仅执行编译操作，不进行链接操作

-std：c++标准

-i：（小写i）：

-I：（大写i）：指定头文件的第一个搜索路径

-l：（小写l）：寻找动态链接库文件

-L：（大写L）：指定第一个寻找库文件的路径







### pkg工具

pkg-config —libs —cflags

### gdb调试

gdb 







### linux命令



将文件的所属权赋给其他用户，命令：

1. 更改文件的所有者:

   chown jim program.c

   文件 program.c 的所有者更改为 jim。作为所有者，jim 可以使用 chmod 命令允许或拒绝其他用户访问 program.c。

2. 更改目录的所有者：

   chown -R john:build /tmp/src

   将目录 /tmp/src 中所有文件的所有者和组更改为用户 john 和组 build

   \- R 递归式地改变指定目录及其下的所有子目录和文件的拥有者。

   \- v 显示chown命令所做的工作。

3. 编程的时候爆killed：

   由于内存爆掉，导致了报错：查看内存使用情况：free -m

4. 解压文件：

   .tar 用 tar –xvf 解压 

   ​	解压到指定路径： tar -xvf xxxx.tar -C ./mysll

   .tar.gz 用tar -xzvf 解压

   .gz 用 gzip -d或者gunzip 解压

   .tar.gz和*.tgz 用 tar –xzf 解压

   

   .bz2 用 bzip2 -d或者用bunzip2 解压

   .tar.bz2用tar –xjf 解压

   .Z 用 uncompress 解压

   .rar 用 unrar e解压

   .zip 用 unzip 解压

5. 文件/文件夹软连接

   ln -s  源地址   目的地址

   删除软连接 rm

   ```python
   ln -s /Volum/dataset ./dataset
   rm ./dataset
   
   #!!!说明：
   #!!!请勿使用 rm ./dataset/   注意最后的‘/’，该语句会删除源文件
   #!!!请勿使用 rm ./dataset/   注意最后的‘/’，该语句会删除源文件
   #!!!请勿使用 rm ./dataset/   注意最后的‘/’，该语句会删除源文件
   ```





查看linux内核版本以及是否是ubuntu或者centos

lsb_release -a



linux关闭防火墙





Linux nohup和&的功效

使用**&**后台运行程序：

- 结果会输出到终端
- 使用Ctrl + C发送SIGINT信号，程序免疫
- 关闭session发送SIGHUP信号，程序关闭

使用**nohup**运行程序：

- 结果默认会输出到nohup.out
- 使用Ctrl + C发送SIGINT信号，程序关闭
- 关闭session发送SIGHUP信号，程序免疫

**平日线上经常使用nohup和&配合来启动程序**：

- 同时免疫SIGINT和SIGHUP信号

同时，还有一个最佳实践：

- 不要将信息输出到终端标准输出，标准错误输出，而要用日志组件将信息记录到日志里



grep 命令

语法

```
grep [-abcEFGhHilLnqrsvVwxy][-A<显示列数>][-B<显示列数>][-C<显示列数>][-d<进行动作>][-e<范本样式>][-f<范本文件>][--help][范本样式][文件或目录...]
```

常用的命令行参数； grep -C20  ‘example’  example.txt

说明：即在example.txt中查找字example所在行，且显示该行之前后的20行信息



**参数**：

- **-a 或 --text** : 不要忽略二进制的数据。
- **-A<显示行数> 或 --after-context=<显示行数>** : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。
- **-b 或 --byte-offset** : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。
- **-B<显示行数> 或 --before-context=<显示行数>** : 除了显示符合样式的那一行之外，并显示该行之前的内容。
- **-c 或 --count** : 计算符合样式的列数。
- **-C<显示行数> 或 --context=<显示行数>或-<显示行数>** : 除了显示符合样式的那一行之外，并显示该行之前后的内容。
- **-d <动作> 或 --directories=<动作>** : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。
- **-e<范本样式> 或 --regexp=<范本样式>** : 指定字符串做为查找文件内容的样式。
- **-E 或 --extended-regexp** : 将样式为延伸的正则表达式来使用。
- **-f<规则文件> 或 --file=<规则文件>** : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。
- **-F 或 --fixed-regexp** : 将样式视为固定字符串的列表。
- **-G 或 --basic-regexp** : 将样式视为普通的表示法来使用。
- **-h 或 --no-filename** : 在显示符合样式的那一行之前，不标示该行所属的文件名称。
- **-H 或 --with-filename** : 在显示符合样式的那一行之前，表示该行所属的文件名称。
- **-i 或 --ignore-case** : 忽略字符大小写的差别。
- **-l 或 --file-with-matches** : 列出文件内容符合指定的样式的文件名称。
- **-L 或 --files-without-match** : 列出文件内容不符合指定的样式的文件名称。
- **-n 或 --line-number** : 在显示符合样式的那一行之前，标示出该行的列数编号。
- **-o 或 --only-matching** : 只显示匹配PATTERN 部分。
- **-q 或 --quiet或--silent** : 不显示任何信息。
- **-r 或 --recursive** : 此参数的效果和指定"-d recurse"参数相同。
- **-s 或 --no-messages** : 不显示错误信息。
- **-v 或 --invert-match** : 显示不包含匹配文本的所有行。
- **-V 或 --version** : 显示版本信息。
- **-w 或 --word-regexp** : 只显示全字符合的列。
- **-x --line-regexp** : 只显示全列符合的列。
- **-y** : 此参数的效果和指定"-i"参数相同。



查看端口被占用信息：

`lsof -i:8080：查看8080端口占用`





### shell学习

#### \$(     ), ${   }, \$((   ))的区别：

 $(.  )是命令替换用(command substitution)的，用于执行shell命令，与``相同，例如

```shell
echo $(date)#$(date)为shell命令输出date
```

${     }用作变量替换，和不加{}相同，添加了{}使得解析器解析的更准确，同时{  }可以用于文本替换等，（待补充）

```shell
echo ${var}
echo $var
```

$(())用于数值计算

```shell
a=1
b=2
echo $(( a+b ))
```

#### 数组

shell中的数组以空格分割，基本定义用`()`实现，例如`array=(123 456 789)`，数组的长度`${#array[*]}`,

数组遍历：

```shell
arrays=(123 456 789);
#len of array
echo ${#arrays[*]};

#遍历
for array in ${array[*]};
do
	echo ${array};
done
```

切片：

```shell
echo ${arrays[@]:1:1}
```



#### 字符串

`string1="asdfasffqwfefsdfxvafd"`

字符串长度：`echo ${#string1}`

字符串:









## spring

spring依赖



参考spring配置文件：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context"
       xmlns:mvc="http://www.springframework.org/schema/mvc"
       xsi:schemaLocation="http://www.springframework.org/schema/beans
       http://www.springframework.org/schema/beans/spring-beans-3.2.xsd
       http://www.springframework.org/schema/context
       http://www.springframework.org/schema/context/spring-context-3.2.xsd
       http://www.springframework.org/schema/mvc
       http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd">
    
<!--    开启注解-->
<context:component-scan base-package="cn.majian">
    <context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/>
</context:component-scan>

</beans>
```



### spring boot



#### 配置文件

配置文件加载优先级：

网上有两种说法：

1. 启动命令中指定的配置项 > 操作系统配置项 > 环境变量 > ==配置中心中的配置文件== >本地的application.properties(yml) > 本地boostrap.properties（yml)

   这几个位置的配置项从前往后优先级递减，即从前面位置加载的配置项会覆盖后面位置加载的配置项。如application.properties中加载的配置项优先级要高于bootstrap.properties中加载的配置项

2. ==配置中心== > 命令行参数 > 操作系统配置项 > 环境变量 > 本地application.yml > 本地bootstrap.yml

本人更倾向于第二种，目前还没有验证

配置文件加载方式：

参考文档：https://blog.csdn.net/dkbnull/article/details/81953190





### spring security



OAUTH四种

- 授权码模式（authorization code）
- 简化模式（implicit）
- 密码模式（resource owner password credentials）
- 客户端模式（client credentials）

参考：http://www.ruanyifeng.com/blog/2019/04/oauth-grant-types.html

#### 资源认证服务器（Auth-server）：



三个配置类：

`SecurityConfiguration、AuthServerConfiguration、PasswordEncoderConfiguration`





`public class SecurityConfig extends WebSecurityConfigurerAdapter `













https://www.cnblogs.com/study-everyday/p/7754596.html



https://blog.csdn.net/u012702547/article/details/89629415







### spring + spring mvc

springmvc依赖

```xml
    <!--spring mvc 依赖-->
    <dependencies>
        <!--spring依赖-->
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-core</artifactId>
            <version>4.3.1.RELEASE</version>
        </dependency>
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-context</artifactId>
            <version>4.3.1.RELEASE</version>
        </dependency>
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-beans</artifactId>
            <version>4.3.1.RELEASE</version>
        </dependency>
        <!--spring依赖结束-->
        <!--springMVC依赖-->
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-web</artifactId>
            <version>4.3.1.RELEASE</version>
        </dependency>
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-webmvc</artifactId>
            <version>4.3.1.RELEASE</version>
        </dependency>
        <!--servelet依赖-->
        <dependency>
            <groupId>javax.servlet</groupId>
            <artifactId>javax.servlet-api</artifactId>
            <version>4.0.1</version>
            <scope>provided</scope>
        </dependency>
        <!--springMVC依赖结束-->
    </dependencies>
```

spring mvc配置步骤：

1. 配置web.xml，即前端控制器dispatchServlet相关属性

   1. 修改web项目下的web.xml文件，配置前端拦截器，同时加载spring mvc的配置文件
   2. 配置前端拦截器中对应的需要拦截的url
   3. 为解决中文乱码的问题，在前端拦截器中配置过滤器，在过滤器中将字符编码集设为utf-8

   参考xml配置如下：

   ```xml
   <!DOCTYPE web-app PUBLIC
    "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN"
    "http://java.sun.com/dtd/web-app_2_3.dtd" >
   
   <web-app>
     <display-name>Archetype Created Web Application</display-name>
   <!--配置前端拦截器，加载spring mvc的配置文件-->
     <servlet>
       <servlet-name>dispatcherServlet</servlet-name>
       <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>
       <init-param>
         <param-name>contextConfigLocation</param-name>
         <param-value>classpath:spring-mvc.xml</param-value>
       </init-param>
       <load-on-startup>1</load-on-startup>
     </servlet>
   
     <servlet-mapping>
       <servlet-name>dispatcherServlet</servlet-name>
       <url-pattern>/</url-pattern>
     </servlet-mapping>
   
     <filter>
       <filter-name>characterEncodingFilter</filter-name>
       <filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>
       <init-param>
         <param-name>encoding</param-name>
         <param-value>UTF-8</param-value>
       </init-param>
     </filter>
     <filter-mapping>
       <filter-name>characterEncodingFilter</filter-name>
       <url-pattern>/*</url-pattern>
     </filter-mapping>
   </web-app>
   ```

2. 配置spring mvc

   1. 开启扫描注解Controller
   2. 配置配置视图解析器
   3. 配置静态资源文件
   4. 开启mvc注解

   参考的spring-mvc.xml：

   ```xml
   <?xml version="1.0" encoding="UTF-8"?>
   <beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context"
          xmlns:mvc="http://www.springframework.org/schema/mvc"
          xsi:schemaLocation="http://www.springframework.org/schema/beans
          http://www.springframework.org/schema/beans/spring-beans-3.2.xsd
          http://www.springframework.org/schema/context
          http://www.springframework.org/schema/context/spring-context-3.2.xsd
          http://www.springframework.org/schema/mvc
          http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd">
   
   <!--    开启bean扫描，基础包为cn.majian-->
       <context:component-scan base-package="cn.majian">
           <context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/>
       </context:component-scan>
   
       <bean id="internalResourceViewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver">
           <property name="prefix" value="/WEB-INF/pages/"/>
           <property name="suffix" value=".jsp"/>
       </bean>
   
       <mvc:resources mapping="/css/**" location="/css/"/>
       <mvc:resources mapping="/images/**" location="/images/"/>
       <mvc:resources mapping="/js/**" location="/js/"/>
   
       <mvc:annotation-driven/>
   </beans>
   ```

   





spring mvc两种方式：

1. 基于注解：

   参考spring实战4

2. 基于xml配置：

    





### spring整合Springmvc

在web.xml中添加spring监听器，加载spring的配置文件，修改web.xml，添加监听器，监听servletcontext生命周期，加载spring配置文件，创建web版本工厂，修改后的web.xml参考如下：

```xml
<!DOCTYPE web-app PUBLIC
 "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN"
 "http://java.sun.com/dtd/web-app_2_3.dtd" >

<web-app>
  <display-name>Archetype Created Web Application</display-name>

<!--配置spring的监听器，默认只加载WEB-INF目录下的applicationContext.xml配置文件-->
  <listener>
    <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
  </listener>
<!--  配置加载文件的路径-->
<context-param>
  <param-name>contextConfigLocation</param-name>
  <param-value>classpath:applicationContext.xml</param-value>
</context-param>

  <servlet>
    <servlet-name>dispatcherServlet</servlet-name>
    <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>
    <init-param>
      <param-name>contextConfigLocation</param-name>
      <param-value>classpath:spring-mvc.xml</param-value>
    </init-param>
    <load-on-startup>1</load-on-startup>
  </servlet>

  <servlet-mapping>
    <servlet-name>dispatcherServlet</servlet-name>
    <url-pattern>/</url-pattern>
  </servlet-mapping>

  <filter>
    <filter-name>characterEncodingFilter</filter-name>
    <filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>
    <init-param>
      <param-name>encoding</param-name>
      <param-value>UTF-8</param-value>
    </init-param>
  </filter>
  <filter-mapping>
    <filter-name>characterEncodingFilter</filter-name>
    <url-pattern>/*</url-pattern>
  </filter-mapping>

</web-app>

```









### maven

maven项目目录结构：

```xml
- ProjectName
  - src/
      - main/
          - java/
              - com/
                  - projectName/
                      ...
                      - controller/
                      - entity/
                      - dao/
                          - mapperInterface.java
                          ...
                      - service/
                      ...
          - resources/
              - com
                  - projectName/
                      - dao/
                          - mapper.xml
                          ...
          - webapp/
              - WEB-INF/
              - index.jsp
      - test/
          - java/
          - resources/


```





maven pom文件

```xml
<!--结点-->
<groupId>com.github.stefanbirkner</groupId>
<artifactId>system-rules</artifactId>
<version>1.16.1</version>
<scope>test</scope>
```

jar包三要素：groupId、artifactId、version确定jar包，从中央仓库下载对应的jar包，无需多说

scope：scope定义了类包在项目的使用阶段。项目阶段包括： 编译，运行，测试和发布。

分类说明
compile
默认scope为compile，表示为当前依赖参与项目的编译、测试和运行阶段，属于强依赖。打包之时，会打到包里去。
test
该依赖仅仅参与测试相关的内容，包括测试用例的编译和执行，比如定性的Junit。
runtime
依赖仅参与运行周期中的使用。一般这种类库都是接口与实现相分离的类库，比如JDBC类库，在编译之时仅依赖相关的接口，在具体的运行之时，才需要具体的mysql、oracle等等数据的驱动程序。
此类的驱动都是为runtime的类库。
provided
该依赖在打包过程中，不需要打进去，这个由运行的环境来提供，比如tomcat或者基础类库等等，事实上，该依赖可以参与编译、测试和运行等周期，与compile等同。区别在于打包阶段进行了exclude操作。
system
使用上与provided相同，不同之处在于该依赖不从maven仓库中提取，而是从本地文件系统中提取，其会参照systemPath的属性进行提取依赖。

当maven依赖本地而非repository中的jar包，sytemPath指明本地jar包路径,样例一如下：

```xml
<dependency>
    <groupid>org.hamcrest</groupid>
    <artifactid>hamcrest-core</artifactid>
    <version>1.5</version>
    <scope>system</scope>
    <systempath>${basedir}/WebContent/WEB-INF/lib/hamcrest-core-1.3.jar</systempath>
</dependency>
```

说明：jar包三要素，scope：system说明该jar包是从本地文件系统提取，提取的路径为systempath中指定的

后续可以多补充一点样例：



idea工程中分module，首先新建一个maven工程，删掉一些非必要的目录结构，pom文件中引入各个子module需要的jar包，同时pom文件中有dependencyManagement结点，如下样例所示

```xml


<dependencyManagement>  
        <dependencies>  
            <dependency>  
                <groupId>org.eclipse.persistence</groupId>  
                <artifactId>org.eclipse.persistence.jpa</artifactId>  
                <version>${org.eclipse.persistence.jpa.version}</version>  
                <scope>provided</scope>  
            </dependency>  
              
            <dependency>  
                <groupId>javax</groupId>  
                <artifactId>javaee-api</artifactId>  
                <version>${javaee-api.version}</version>  
            </dependency>  
        </dependencies>  
</dependencyManagement>  
```





```xml
<parent>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-parent</artifactId>
    <version>1.0.2.BUILD-SNAPSHOT</version>
</parent>


```





plugin

待整理













问题：

1. idea中配置maven对应的路径后，退出打开后还是会恢复到默认的设置：

   解决方法：修改idea中的设置，设置完成后还需要删除C:\Users\user\.m2文件夹

2. idea新建工程，java comile默认为1.5

   解决方法：在pom文件中的plugins结点下添加如下：

   ```xml
   <build>
       <plugins>
           <plugin>
               <groupId>org.apache.maven.plugins</groupId>
               <artifactId>maven-compiler-plugin</artifactId>
               <version>2.3.2</version>
               <configuration>
                   <source>1.8</source>
                   <target>1.8</target>
               </configuration>
           </plugin>
       </plugins>
   </build>
   ```







### 日志

为了在系统中做日志记录，需要引入jar包

```xml
<properties>
  <sl4fj.version>1.6.6</sl4fj.version>
  <log4j.version>1.2.12</log4j.version>
</properties>

<dependency>
  <groupId>log4j</groupId>
  <artifactId>log4j</artifactId>
  <version>${log4j.version}</version>
</dependency>

<dependency>
  <groupId>org.slf4j</groupId>
  <artifactId>slf4j-api</artifactId>
  <version>${sl4fj.version}</version>
</dependency>

<dependency>
  <groupId>org.slf4j</groupId>
  <artifactId>slf4j-log4j12</artifactId>
  <version>${sl4fj.version}</version>
</dependency>
```



### 日志接口slf4j

日志实现类log4j、logback、log4j2等

### log4j

log4j配置说明：

```pr
#配置根Logger
log4j.rootLogger  =   [ level ]   ,  appenderName ,  appenderName1 ,  …

#配置日志信息输出目的地Appender及Appender选项

log4j.appender.appenderName = fully.qualified.name.of.appender.class 　　

　　log4j.appender.appenderName.option = value1
 　　　　… 　　
　　log4j.appender.appenderName.optionN = valueN 
#配置日志信息的格式（布局）及格式布局选项 
appender.appenderName.layout = fully.log4j.qualified.name.of.layout.class
　　log4j.appender.appenderName.layout.option1 = value1
 　　　　… 　　
　　log4j.appender.appenderName.layout.optionN = valueN
```



其中 [ level ] 是日志输出级别：ERROR、WARN、INFO、DEBUG
ERROR 为严重错误 主要是程序的错误
WARN 为一般警告，比如session丢失
INFO 为一般要显示的信息，比如登录登出
DEBUG 为程序的调试信息
appenderName是日志输出位置的配置的命名
log4j.appender.appenderName = fully.qualified.name.of.appender.class中fully.qualified.name.of.appender.class应换上以下信息输出的目的地：

```
org.apache.log4j.ConsoleAppender（控制台）
org.apache.log4j.FileAppender（文件）
org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）
org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）
org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）
 
appender.appenderName.layout = fully.log4j.qualified.name.of.layout.class中fully.qualified.name.of.layout.class格式布局应换上以下信息：
org.apache.log4j.HTMLLayout（以HTML表格形式布局）
org.apache.log4j.PatternLayout（可以灵活地指定布局模式）
org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）
org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）
log4j.appender.appenderName.option中option应替换的属性/选项
 
　　1.ConsoleAppender控制台选项
　　　　Threshold=DEBUG:指定日志消息的输出最低层次。
　　　　ImmediateFlush=true:默认值是true,意味着所有的消息都会被立即输出。
　　　　Target=System.err：默认情况下是：System.out,指定输出控制台
　　2.FileAppender 文件选项
　　　　Threshold=DEBUF:指定日志消息的输出最低层次。
　　　　ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。
　　　　File=mylog.txt:指定消息输出到mylog.txt文件。
　　　　Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。
　　3.RollingFileAppender 每天生成一个文件选项
　　　　Threshold=DEBUG:指定日志消息的输出最低层次。
　　　　ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。
　　　　File=mylog.txt:指定消息输出到mylog.txt文件。
　　　　Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。
　　　　MaxFileSize=100KB: 后缀可以是KB, MB 或者是 GB. 在日志文件到达该大小时，将会自动滚动，即将原来的内容移到mylog.log.1文件。
　　　　MaxBackupIndex=2:指定可以产生的滚动文件的最大数。
```

log4j配置文件log4j.properties

```properties
### 设置###
log4j.rootLogger = debug,stdout,D,E
 
### 输出信息到控制抬 ###
log4j.appender.stdout = org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target = System.out
log4j.appender.stdout.layout = org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern = [%-5p] %d{yyyy-MM-dd HH:mm:ss,SSS} method:%l%n%m%n
 
### 输出DEBUG 级别以上的日志到=E://logs/debug-log.log ###
log4j.appender.D = org.apache.log4j.DailyRollingFileAppender
log4j.appender.D.File = E://logs/debuglog.log
log4j.appender.D.Append = true
log4j.appender.D.Threshold = DEBUG 
log4j.appender.D.layout = org.apache.log4j.PatternLayout
log4j.appender.D.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss}  [ %t:%r ] - [ %p ]  %m%n
 
### 输出ERROR 级别以上的日志到=E://logs/error.log ###
log4j.appender.E = org.apache.log4j.DailyRollingFileAppender
log4j.appender.E.File =E://logs/error.log 
log4j.appender.E.Append = true
log4j.appender.E.Threshold = ERROR 
log4j.appender.E.layout = org.apache.log4j.PatternLayout
log4j.appender.E.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss}  [ %t:%r ] - [ %p ]  %m%n
```





Logback配置文件：logback-spring.xml,参考：https://www.cnblogs.com/wuyoucao/p/10983241.html

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!-- 日志级别从低到高分为TRACE < DEBUG < INFO < WARN < ERROR < FATAL，如果设置为WARN，则低于WARN的信息都不会输出 -->
<!-- scan:当此属性设置为true时，配置文档如果发生改变，将会被重新加载，默认值为true -->
<!-- scanPeriod:设置监测配置文档是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。
                 当scan为true时，此属性生效。默认的时间间隔为1分钟。 -->
<!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 -->
<configuration  scan="true" scanPeriod="10 seconds">
    <contextName>logback</contextName>

    <!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义后，可以使“${}”来使用变量。 -->
    <property name="log.path" value="./logs/" />

    <!--0. 日志格式和颜色渲染 -->
    <!-- 彩色日志依赖的渲染类 -->
    <conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter" />
    <conversionRule conversionWord="wex" converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter" />
    <conversionRule conversionWord="wEx" converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter" />
    <!-- 彩色日志格式 -->
    <property name="CONSOLE_LOG_PATTERN" value="${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/>

    <!--1. 输出到控制台-->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息-->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>debug</level>
        </filter>
        <encoder>
            <Pattern>${CONSOLE_LOG_PATTERN}</Pattern>
            <!-- 设置字符集 -->
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!--2. 输出到文档-->
    <!-- 2.1 level为 DEBUG 日志，时间滚动输出  -->
    <appender name="DEBUG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 正在记录的日志文档的路径及文档名 -->
        <file>${log.path}/web-debug.log</file>
        <!--日志文档输出格式-->
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset> <!-- 设置字符集 -->
        </encoder>
        <!-- 日志记录器的滚动策略，按日期，按大小记录 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志归档 -->
            <fileNamePattern>${log.path}/web-debug-%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>100MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <!--日志文档保留天数-->
            <maxHistory>15</maxHistory>
        </rollingPolicy>
        <!-- 此日志文档只记录debug级别的 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>debug</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <!-- 2.2 level为 INFO 日志，时间滚动输出  -->
    <appender name="INFO_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 正在记录的日志文档的路径及文档名 -->
        <file>${log.path}/web-info.log</file>
        <!--日志文档输出格式-->
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 日志记录器的滚动策略，按日期，按大小记录 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 每天日志归档路径以及格式 -->
            <fileNamePattern>${log.path}/web-info-%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>100MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <!--日志文档保留天数-->
            <maxHistory>15</maxHistory>
        </rollingPolicy>
        <!-- 此日志文档只记录info级别的 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>info</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <!-- 2.3 level为 WARN 日志，时间滚动输出  -->
    <appender name="WARN_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 正在记录的日志文档的路径及文档名 -->
        <file>${log.path}/web-warn.log</file>
        <!--日志文档输出格式-->
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset> <!-- 此处设置字符集 -->
        </encoder>
        <!-- 日志记录器的滚动策略，按日期，按大小记录 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${log.path}/web-warn-%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>100MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <!--日志文档保留天数-->
            <maxHistory>15</maxHistory>
        </rollingPolicy>
        <!-- 此日志文档只记录warn级别的 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>warn</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <!-- 2.4 level为 ERROR 日志，时间滚动输出  -->
    <appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 正在记录的日志文档的路径及文档名 -->
        <file>${log.path}/web-error.log</file>
        <!--日志文档输出格式-->
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset> <!-- 此处设置字符集 -->
        </encoder>
        <!-- 日志记录器的滚动策略，按日期，按大小记录 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${log.path}/web-error-%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>100MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <!--日志文档保留天数-->
            <maxHistory>15</maxHistory>
        </rollingPolicy>
        <!-- 此日志文档只记录ERROR级别的 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <!--
        <logger>用来设置某一个包或者具体的某一个类的日志打印级别、
        以及指定<appender>。<logger>仅有一个name属性，
        一个可选的level和一个可选的addtivity属性。
        name:用来指定受此logger约束的某一个包或者具体的某一个类。
        level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，
              还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。
              如果未设置此属性，那么当前logger将会继承上级的级别。
        addtivity:是否向上级logger传递打印信息。默认是true。
        <logger name="org.springframework.web" level="info"/>
        <logger name="org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor" level="INFO"/>
    -->

    <!--
        使用mybatis的时候，sql语句是debug下才会打印，而这里我们只配置了info，所以想要查看sql语句的话，有以下两种操作：
        第一种把<root level="info">改成<root level="DEBUG">这样就会打印sql，不过这样日志那边会出现很多其他消息
        第二种就是单独给dao下目录配置debug模式，代码如下，这样配置sql语句会打印，其他还是正常info级别：
        【logging.level.org.mybatis=debug logging.level.dao=debug】
     -->

    <!--
        root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性
        level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，
        不能设置为INHERITED或者同义词NULL。默认是DEBUG
        可以包含零个或多个元素，标识这个appender将会添加到这个logger。
    -->

    <!-- 4. 最终的策略 -->
    <!-- 4.1 开发环境:打印控制台-->
    <!--logger name 为需要记录日志的包名，默认级别为root指定的级别-->

    <springProfile name="dev">
        <logger name="org.example" level="debug"/>
    </springProfile>

    <root level="info">
        <appender-ref ref="CONSOLE" />
        <appender-ref ref="DEBUG_FILE" />
        <appender-ref ref="INFO_FILE" />
        <appender-ref ref="WARN_FILE" />
        <appender-ref ref="ERROR_FILE" />
    </root>

    <!-- 4.2 生产环境:输出到文档
    <springProfile name="pro">
        <root level="info">
            <appender-ref ref="CONSOLE" />
            <appender-ref ref="DEBUG_FILE" />
            <appender-ref ref="INFO_FILE" />
            <appender-ref ref="ERROR_FILE" />
            <appender-ref ref="WARN_FILE" />
        </root>
    </springProfile> -->

</configuration>
```







### junit



依赖：

```xml
<!--测试依赖-->
<dependency>
    <groupId>junit</groupId>
    <artifactId>junit</artifactId>
    <version>4.12</version>
</dependency>
```







## Restful风格介绍

https://blog.csdn.net/lupengfei1009/article/details/107316856

https://www.cnblogs.com/xuwujing/p/8260935.html





## RabbitMq





## 阿里云

公网IP地址：47.103.10.87

RabbitMq用户名/密码：guest/guest，页面地址：http://47.103.10.87:15672/#/





## git教程

git init

说明：初始化git仓库

git add

说明：将修改的内容提交到暂存区中

git commit

说明：将暂存中的内容提交到仓库中

git status

说明：查看当前仓库的状态

git diff

说明：比较文件在暂存区和工作区的差异

git log

说明：查看提交的日志记录

git branch -a

说明：查看所有分支

git checkout ：

说明：

git checkout -b mybranch切换并创建分支

git checkout mybranch 切换分支

git merge

说明：git merge b 为将分支b合并到当前分支上

git rebase

说明：git rebase b 为将分支b合并到当前分支上，和git merge功能相似，禁止使用，当需要合并分支的时候，用git merge命令

git show

说明：使用样例：git show 356f6def9d3fb7f3b9032ff5aa4b9110d4cca87e，356f。。。为每次提交的hash值，通过git log查看

==常见的回退操作：==

1. 本地修改了一些文件 (并没有使用 git add 到暂存区)，想放弃修改

- 单个文件/文件夹：

  ```shell
  git checkout -- filename
  ```

- 所有文件/文件夹：

  ```shell
  git checkout .
  ```

2. 本地新增了一些文件 (并没有 git add 到暂存区)，想放弃修改

- 单个文件/文件夹：

  ```shell
  rm  -rf filename
  ```

- 所有文件：

  ```shell
  git clean -xdf
  ```

  > 删除新增的文件，如果文件已经已经 git add 到暂存区，并不会删除！

- 所有文件和文件夹：

  ```shell
  git clean -xdff
  ```

  > [谨慎操作] 本命令删除新增的文件和文件夹，如果文件已经已经 git add 到暂存区，并不会删除！

3. 本地修改/新增了一些文件，已经 git add 到暂存区，想放弃修改

- 单个文件/文件夹：

  ```shell
  git reset HEAD filename
  ```

- 所有文件/文件夹：

  ```shell
  git reset HEAD .
  ```

4. 本地通过 git add 和 git commit 后，想要撤销此次 commit

- 撤销 commit, 同时保留该 commit 修改：

  ```shell
  git reset commit_id
  ```

  这个 `commit_id` 是你想要回到的那个节点，可以通过 git log 查看，可以只选前 6 位。

  > 撤销之后，你所做的已经 commit 的修改还在工作区！

- 撤销 commit, 同时本地删除该 commit 修改：

  ```shell
  git reset --hard commit_id
  ```

  这个 `commit_id` 是你想要回到的那个节点，可以通过 git log 查看，可以只选前6位

  > [谨慎操作] 撤销之后，你所做的已经 commit 的修改将会清除，仍在工作区/暂存区的代码也将会清除！



**明确一点：**在idea中

如果项目交给git管理了【[如何将项目交给git管理](https://www.cnblogs.com/sxdcgaq8080/p/8058898.html)：https://www.cnblogs.com/sxdcgaq8080/p/8058898.html】

**1.若文件显示红色，表示文件未add到git进行管理**

**2.若文件显示绿色，表示文件已经交给git管理，但从未上传到远程仓库中**

**3.若文件显示蓝色，表示文件已经上传过远程仓库，且此时本地文件与远程仓库文件不一致**

**4.若文件显示白色，表示文件与远程仓库完全一致**



忽略文件：

1、未track



2、已track

参考文档：https://blog.csdn.net/fzx19910714/article/details/78821616

https://www.jianshu.com/p/699ed86028c2

git rm -r -f --cache .



查看本地分支与远程分支的关联关系：

git branch -vv

git remote rm origin 删除现有远程仓库

git remote add origin url 添加新远程仓



推送到远程仓库：

git push origin 分支名(dev-majian)



本地分支与远程分支关联：

git branch --set-upstream-to=origin/分支名(dev-majian)





## java异常处理





## 端口被占用



### windows

查看端口49153被占用情况：

netstat -aon|findstr "49153"，回车，记下最后一位数字，即PID，这里是1008

tasklist|findstr "1008"，回车，查看是哪个进程或者程序占用了1008端口



### linux

netstat -anp |grep 3306





## docker安装

win10安装：

docker对win10的支持为对64位Windows 10 Pro，专业版、企业版和教育版（1607年纪念更新，版本14393或更高版本）上，家庭版是不行的，家庭版的安装需要参考win7系统的安装，因公司的电脑为家庭版，安装的时候遇到了很多的问题。

安装的版本地址：https://pan.baidu.com/s/1cQ4sNf4Eu_d0VViloS7GUg 
提取码：t28t 

安装两个包：

首先安装VirtualBox-6.1.16-140961-Win.exe，安装虚拟机

然后在安装DockerToolbox-18.03.0-ce.exe，需要注意不要再次安装虚拟机了

安装完成后，由于默认的仓库为境外网站，速度奇慢无比，需要修改仓库路径为国内的镜像仓库源

打开docker-quickstart，输入如下命令：

```shell
docker-machine ssh
sudo vi /var/lib/boot2docker/profile

在打开的文件中，在
--label provider=virtualbox的下一行添加

--registry-mirror https://docker.mirrors.ustc.edu.cn

exit

docker-machine restart
```





创建镜像：

docker build -t  大版本：小版本 .

dockerfile中添加环境变量：

ARG KE_HOME=/usr/local/kafka-eagle-web-1.2.4
ENV KE_HOME=$KE_HOME



docker images



重新启动容器：

docker restart 容器ID



查看容器相关信息：

docker inspect 容器ID



docker [image] inspect命令可以获取该镜像的详细信息，包括制作者、适应架构、各层的数字摘要等：



### docker-compose教程

在windows上安装docker后，默认是安装了docker-compose了，因此可以直接使用





以安装mysql为例，新建docker-compose.yml文件

```yaml
version: '3.1'
services:
  mysql:
    image: mysql:5.7
    container_name: mysql
    privileged: true #一定要设置为true，不然数据卷可能挂载不了，启动不起
    ports: 
     - 3306:3306
    environment:
      MYSQL_ROOT_PASSWORD: 123456 # 自己配置数据库密码
      TZ: Asia/Shanghai
      MYSQL_USER: root
      MYSQL_PASS: 123456
    command:
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_general_ci
      --explicit_defaults_for_timestamp=true
      --lower_case_table_names=1
      --max_allowed_packet=128M
      --sql-mode="STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO"   
    ##volumes:里面的参数为映射本地和docker容器里面的文件夹和目录
    volumes:
      - ./data:/var/lib/mysql
      - ./conf/my.cnf:/etc/my.cnf
    restart: always
```

my.cnf文件：

```yaml
[mysqld]
user=mysql
default-storage-engine=INNODB
character-set-server=utf8mb6
default-time_zone = '+8:00'
sql-mode=STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION
[client]
default-character-set=utf8
[mysql]
default-character-set=utf8
```

之后进入到mysql目录下，输入启动命令

`docker-compose up`

如果你想在后台执行该服务可以加上 -d 参数

`docker-compose up -d`

停服务：

`docker-compose down`





## k8s



查看namespace：

kubectl get namespace

创建新的namespace "pingpang"

kubectl create namespace pingpang 

查看deployment：

kubectl get deployment



查看服务：

kubectl get service

查看服务详细信息：

kubectl describe service/（服务名）



查看pod：





删除pod：





kubectl delete service hello-node 

kubectl delete deployment hello-node





yaml格式的pod定义文件完整内容：

```yaml
# 必选，版本号，例如v1,此值必须在kubectl -apiversions中 
apiVersion: v1
#必选，三种：Pod、service、deployment
kind: Pod     
#必选，元数据，资源的元数据/属性
metadata:       
  name: string       #必选，Pod名称
  namespace: string    #必选，Pod所属的命名空间
  labels:      #自定义标签
    - name: string     #自定义标签名字
  annotations:       #自定义注释列表
    - name: string
spec:         #必选，Pod中容器的详细定义
  containers:      #必选，Pod中容器列表
  - name: string     #必选，容器名称
    image: string    #必选，容器的镜像名称
    imagePullPolicy: [Always | Never | IfNotPresent] #获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像
    command: [string]    #容器的启动命令列表，如不指定，使用打包时使用的启动命令
    args: [string]     #容器的启动命令参数列表
    workingDir: string     #容器的工作目录
    volumeMounts:    #挂载到容器内部的存储卷配置
    - name: string     #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名
      mountPath: string    #存储卷在容器内mount的绝对路径，应少于512字符
      readOnly: boolean    #是否为只读模式
    ports:       #需要暴露的端口库号列表
    - name: string     #端口号名称
      containerPort: int   #容器需要监听的端口号
      hostPort: int    #容器所在主机需要监听的端口号，默认与Container相同
      protocol: string     #端口协议，支持TCP和UDP，默认TCP
    env:       #容器运行前需设置的环境变量列表
    - name: string     #环境变量名称
      value: string    #环境变量的值
    resources:       #资源限制和请求的设置
      limits:      #资源限制的设置
        cpu: string    #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数
        memory: string     #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数
      requests:      #资源请求的设置
        cpu: string    #Cpu请求，容器启动的初始可用数量
        memory: string     #内存清楚，容器启动的初始可用数量
    livenessProbe:     #对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可
      exec:      #对Pod容器内检查方式设置为exec方式
        command: [string]  #exec方式需要制定的命令或脚本
      httpGet:       #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port
        path: string
        port: number
        host: string
        scheme: string
        HttpHeaders:
        - name: string
          value: string
      tcpSocket:     #对Pod内个容器健康检查方式设置为tcpSocket方式
         port: number
       initialDelaySeconds: 0  #容器启动完成后首次探测的时间，单位为秒
       timeoutSeconds: 0   #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒
       periodSeconds: 0    #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次
       successThreshold: 0
       failureThreshold: 0
       securityContext:
         privileged:false
    restartPolicy: [Always | Never | OnFailure]#Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod
    nodeSelector: obeject  #设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定
    imagePullSecrets:    #Pull镜像时使用的secret名称，以key：secretkey格式指定
    - name: string
    hostNetwork:false      #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络
    volumes:       #在该pod上定义共享存储卷列表
    - name: string     #共享存储卷名称 （volumes类型有很多种）
      emptyDir: {}     #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值
      hostPath: string     #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录
        path: string     #Pod所在宿主机的目录，将被用于同期中mount的目录
      secret:      #类型为secret的存储卷，挂载集群与定义的secre对象到容器内部
        scretname: string  
        items:     
        - key: string
          path: string
      configMap:     #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部
        name: string
        items:
        - key: string
          path: string
```





deployment参考样例：

nginx-deployment.yaml

```yaml
apiVersion: apps/v1   # 1.9.0 之前的版本使用 apps/v1beta2，可通过命令 kubectl api-versions 查看
kind: Deployment 	#指定创建资源的角色/类型
metadata: 	 #资源的元数据/属性
  name: nginx-deployment	#资源的名字，在同一个namespace中必须唯一
spec:
  replicas: 2 	 #副本数量2
  selector:      #定义标签选择器
    matchLabels:
      app: web-server
  template: 	 #这里Pod的定义
    metadata:
      labels: 	 #Pod的label
        app: web-server
    spec:		 # 指定该资源的内容  
      containers:  
      - name: nginx 	 #容器的名字  
        image: nginx:1.12.1  #容器的镜像地址    
        ports:  
        - containerPort: 80  #容器对外的端口
```

执行`kubectl create -f nginx.yaml`创建 deployment 资源



pod参考样例：

```yaml
apiVersion: apps/v1
kind: Pod  
metadata:  
  name: pod-redis
  labels:
    name: redis
    
spec: 
  containers:
    name: pod-redis
    image: docker.io/redis  
    ports:
      containerPort: 80	#容器对外的端口
```

执行`kubectl create -f pod-redis.yaml`创建 pod 资源



service样例：

```yaml
apiVersion: v1  
kind: Service  # 指明资源类型是 service
metadata:  
  name: httpd-svc # service 的名字是 httpd-svc
  labels:  
    name: httpd-svc 
spec:  
  ports:  # 将 service 8080 端口映射到 pod 的 80 端口，使用 TCP 协议
  - port: 8080
    targetPort: 80  
    protocol: TCP  
  selector:  
    run: httpd # 指明哪些 label 的 pod 作为 service 的后端
```

执行`kubectl create -f httpd-svc.yaml`创建 service 资源













